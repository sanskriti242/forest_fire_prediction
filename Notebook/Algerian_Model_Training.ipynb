{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Algerian_Model_Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load clean dataset\n",
    "df = pd.read_csv(\"Algerian_Forest_firesdataset_Cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop month day and year\n",
    "df.drop(['day','month','year'],axis = 1,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Classes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the other 'not fire' and use only fire and 'not fire'\n",
    "df['Classes'] = np.where(df['Classes'].str.contains('not fire'),0,1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent features and dependent features\n",
    "X = df.drop('FWI',axis= 1)\n",
    "y = df['FWI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 1. Feature selection based on Correlation\n",
    "\n",
    "Remove - highly positively correlated Important = highly negatively correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Check for multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "corr = X_train.corr()\n",
    "sns.heatmap(corr,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove highly positively correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## threshold -- Domain expertise... here we are giving 85% correlation\n",
    "corr_featuers = correlation(X_train, 0.85) #greater than 85%\n",
    "\n",
    "corr_featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the highly correlated features (more than 85%\n",
    "X_train.drop(corr_featuers,axis=1,inplace=True)\n",
    "X_test.drop(corr_featuers,axis=1,inplace=True)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### Feature Scaling or Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Box plot to understand effect of standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotbox plot\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(data=X_train)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title ('Before scaling')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data=X_train_scaled)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title ('After scaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled,y_train)\n",
    "y_pred = linreg.predict(X_test_scaled)\n",
    "mae= mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(\"Mean absolute error\",mae)\n",
    "print(\"R2 score\",score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 2. Lasso Regerssion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled,y_train)\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(\"Mean absolute error\",mae)\n",
    "print(\"R2 score\",score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 3. Cross Validation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lassocv = LassoCV(cv=5)\n",
    "lassocv.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what all the alphas that it tried\n",
    "lassocv.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv.mse_path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lassocv.predict(X_test_scaled)\n",
    "plt.scatter(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(\"Mean absolute eror\",mae)\n",
    "print(\"R2 Score\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### 4. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled,y_train)\n",
    "y_pred = ridge.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(\"Mean absolute eror\",mae)\n",
    "print(\"R2 Score\",score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### 5. Ridge Regression CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridgecv = RidgeCV(cv=5)\n",
    "ridgecv.fit(X_train_scaled,y_train)\n",
    "y_pred = ridgecv.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(\"Mean absolute eror\",mae)\n",
    "print(\"R2 Score\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 6. ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elasticNet = ElasticNet()\n",
    "elasticNet.fit(X_train_scaled, y_train)\n",
    "y_pred = elasticNet.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "print(\"R2 Score: \", r2)\n",
    "plt.scatter(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### 7. ElasticNet CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "elasticNetCV = ElasticNetCV(cv=5)\n",
    "elasticNetCV.fit(X_train_scaled, y_train)\n",
    "plt.scatter(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "print(\"R2 Score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "#### Model Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "pickle.dump(ridge, open('ridge.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## Summary of Linear Regression Model Selection\n",
    "\n",
    "Based on the evaluation of various linear regression models, **Ridge Regression emerges as a strong and likely the right choice** for this prediction task.\n",
    "\n",
    "**Performance Comparison:**\n",
    "\n",
    "| Model             | Mean Absolute Error (MAE) | R2 Score | Regularization | Feature Selection |\n",
    "|-------------------|---------------------------|----------|----------------|-------------------|\n",
    "| Linear Regression | 0.5648                    | 0.9847   | None           | No                |\n",
    "| Lasso             | 1.1203                    | 0.9511   | L1             | Yes (potential)   |\n",
    "| LassoCV           | 0.6356                    | 0.9822   | L1 (CV Tuned)  | Yes (potential)   |\n",
    "| **Ridge** | **0.5845** | **0.9842** | **L2** | **No** |\n",
    "| RidgeCV           | 0.7943                    | 0.9762   | L2 (CV Tuned)  | No                |\n",
    "| Elastic Net       | 1.8555                    | 0.8804   | L1 & L2        | Yes (potential)   |\n",
    "| ElasticNetCV      | 1.8555 (Incorrect Eval)   | 0.8804 (Incorrect Eval) | L1 & L2 (CV Tuned)| Yes (potential)   |\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "* **Ridge Regression** achieved an R2 score (0.9842) and MAE (0.5845) very close to the best-performing Linear Regression (R2: 0.9847, MAE: 0.5648).\n",
    "* **Regularization Benefit:** Ridge's L2 regularization offers potential benefits in handling multicollinearity and preventing overfitting without significantly sacrificing predictive performance compared to simple Linear Regression.\n",
    "* **Lasso and Elastic Net:** While these models offer feature selection capabilities, their performance with default parameters was generally lower. LassoCV showed improvement but didn't surpass Ridge. The ElasticNetCV evaluation was flawed and requires correction.\n",
    "* **RidgeCV:** Cross-validation for Ridge with default alpha values did not improve upon the performance of the simple Ridge model.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "Given the high R2 score and low MAE, coupled with the benefits of L2 regularization for robustness, **Ridge Regression appears to be the most suitable choice among the tested models for this prediction task.** While simple Linear Regression performed slightly better on the test set, Ridge offers a good balance of predictive accuracy and potential for better generalization due to regularization. Further hyperparameter tuning of Ridge could potentially yield even better results. The primary goal of the modeling and the importance of coefficient interpretability should also be considered in the final decision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
